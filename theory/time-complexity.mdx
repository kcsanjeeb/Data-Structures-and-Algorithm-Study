---
title: "Complexity Calculation (My Simple Way)"
description: "A simple and clear explanation of time and space complexity for coding interviews."
---

## **Complexity Calculation (My Simple Way)**

---

# **ðŸ•’ Time Complexity**

### **1. Single Loop**
```go
for i := 0; i < n; i++ {    // runs n times
    x = y + z               // constant time (c)
}
```

- Total time = `c * n`  
- In Big-O, we ignore constants â‡’ **O(n)**

---

### **2. Nested Loop**
```go
for i := 0; i < n; i++ {        // n times
    for j := 1; j < n; j++ {    // n times
        x = y + z               // constant time (c)
    }
}
```

- Total time = `n * n * c = c * nÂ²`  
- Ignoring constant `c` â‡’ **O(nÂ²)**

---

### **3. Sequential Statements**
```go
a = a + b         // constant time câ‚

for i := 0; i < n; i++ {    // n times
    x = y + z               // constant time câ‚‚
}

for j := 0; j < n; j++ {    // n times
    j = k + l               // constant time câ‚ƒ
}
```

- Total = `câ‚ + n*câ‚‚ + n*câ‚ƒ`  
- Ignore constants â‡’ `n + n = 2n â‰ˆ O(n)`  
âœ… **Final complexity: O(n)**

---

### **4. If-Else Statements**
```go
if condition {
    // Suppose this block has O(n)
} else {
    // Suppose this block has O(nÂ²)
}
```

- The total complexity = **max(O(n), O(nÂ²)) = O(nÂ²)**  
- Always consider the **worst-case** branch.

---

### **Hierarchy of Common Complexities**

| Notation | Description | Example |
|-----------|--------------|----------|
| O(1) | Constant | Access by index |
| O(log n) | Logarithmic | Binary search |
| O(n) | Linear | Single loop |
| O(n log n) | Log-linear | Merge sort |
| O(nÂ²) | Quadratic | Nested loops |
| O(nÂ³) | Cubic | 3 nested loops |
| O(2â¿) | Exponential | Recursion with 2 branches |
| O(n!) | Factorial | Permutation generation |

ðŸ“ˆ **Order of Growth (from best â†’ worst):**

> O(1) < O(log n) < O(n) < O(n log n) < O(nÂ²) < O(2â¿) < O(n!)

---

![Sorting And Searching Algorithms - Time Complexities Cheat Sheet | HackerEarth](https://he-s3.s3.amazonaws.com/media/uploads/c950295.png)

---

# **ðŸ’¾ Space Complexity**

Letâ€™s assume an `int` takes **4 bytes** of memory:

```go
var a int       // 4 bytes
var b int       // 4 bytes
var c int       // 4 bytes
var z int       
z = a + b + c   // 4 bytes
return z        // 4 bytes
```

- Total memory = `4 * 4 + 4(return)` = **20 bytes**

âœ… Hence, **Space Complexity = O(1)**  
(because itâ€™s constant, independent of input size)

---

## **âš–ï¸ Spaceâ€“Time Trade-Off and Efficiency**

- Thereâ€™s always a **trade-off between memory usage and runtime performance.**  
- **Space efficiency** and **time efficiency** often move in opposite directions.  
- More memory (space) â†’ faster algorithms (less recomputation).  
- Less memory â†’ slower algorithms (more recomputation).

ðŸ’¡ **Rule of thumb:**  
> The goal is not to minimize one, but to balance both for your use case.
